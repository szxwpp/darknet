[net]
# Testing
batch=1
subdivisions=1
# Training
# batch=64
# subdivisions=2
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 50000
policy=steps
steps=8000,15000,25000,35000
scales=.1,.1,.1,.1

[convolutional]
batch_normalize=1
filters=15
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=30
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=60
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=100
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=50
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=100
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=160
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=80
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=160
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=260
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=130
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=260
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=30
activation=linear

[region]
anchors = 1.7797,2.2130, 2.7474,3.9476, 4.4201,6.3076, 6.0405,8.0591, 9.6157,8.1542
bias_match=1
classes=1
coords=4
num=5
softmax=1
jitter=.2
rescore=0
#focal_loss=1

object_scale=5
noobject_scale=1
class_scale=1
coord_scale=1

absolute=1
thresh = .6
random=1
